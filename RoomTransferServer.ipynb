{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvUhQ7IKV2OZqKYrT76arM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajeshj4all/roominterior/blob/feature%2Fdev/RoomTransferServer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers torch torchvision torchaudio\n",
        "!pip install scikit-image\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Jc0CnAbouUsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG_8MDENxrlG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import gc\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, StableDiffusionImg2ImgPipeline\n",
        "import gradio as gr\n",
        "from PIL import Image, ImageEnhance\n",
        "import numpy as np\n",
        "from skimage import feature, color\n",
        "import os\n",
        "\n",
        "# Create a debug directory if it doesn't exist\n",
        "os.makedirs(\"debug\", exist_ok=True)\n",
        "\n",
        "def preprocess_image(room_image):\n",
        "    \"\"\"Process the input room image to prepare it for the model\"\"\"\n",
        "    # Save original for debugging\n",
        "    room_image.save(\"debug/reference_original.png\")\n",
        "\n",
        "    # Convert to RGB\n",
        "    image = room_image.convert(\"RGB\")\n",
        "    image.save(\"debug/reference_rgb.png\")\n",
        "\n",
        "    # Check pixel data to detect potential issues with the input image\n",
        "    pixels = list(image.getdata())  # Fixed: Changed rgb_image to image\n",
        "    unique_pixels = len(set(pixels))\n",
        "    print(f\"Unique pixel count: {unique_pixels}\")\n",
        "\n",
        "    if unique_pixels < 100:\n",
        "        print(\"WARNING: Reference image has very few unique colors\")\n",
        "\n",
        "    # Resize to 768x768 for better quality\n",
        "    image = image.resize((768, 768), Image.LANCZOS)\n",
        "    image.save(\"debug/reference_sample.png\")  # Fixed: Added quotes\n",
        "\n",
        "    # Convert to numpy array for edge detection\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Edge detection with optimized parameters\n",
        "    edges = feature.canny(\n",
        "        color.rgb2gray(image_np),\n",
        "        sigma=1.5,\n",
        "        low_threshold=0.1,\n",
        "        high_threshold=0.2\n",
        "    ).astype(np.uint8) * 255\n",
        "\n",
        "    edges_image = Image.fromarray(edges)\n",
        "    edges_image.save(\"debug/edges.png\")\n",
        "\n",
        "    return image, edges_image\n",
        "\n",
        "def analyze_reference_image(reference_image):\n",
        "    \"\"\"Analyze reference image to extract key features for style transfer\"\"\"\n",
        "    reference_image = reference_image.convert(\"RGB\")\n",
        "    reference_image.save(\"debug/reference_image.png\")\n",
        "\n",
        "    # Resize reference image to match our working size\n",
        "    reference_image = reference_image.resize((768, 768), Image.LANCZOS)\n",
        "\n",
        "    # We could add more sophisticated analysis here:\n",
        "    # - Color palette extraction\n",
        "    # - Texture analysis\n",
        "    # - Style features\n",
        "\n",
        "    return reference_image\n",
        "\n",
        "def enhance_output(image):\n",
        "    \"\"\"Post-process the generated image for better quality\"\"\"\n",
        "    # Apply sharpening\n",
        "    enhancer = ImageEnhance.Sharpness(image)\n",
        "    image = enhancer.enhance(1.2)\n",
        "\n",
        "    # Improve contrast\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(1.1)\n",
        "\n",
        "    # Enhance colors\n",
        "    enhancer = ImageEnhance.Color(image)\n",
        "    image = enhancer.enhance(1.1)\n",
        "\n",
        "    return image\n",
        "\n",
        "def transform_room(room_image, reference_image, theme, room_type, specific_items, include_reference=False):\n",
        "    \"\"\"Main function to transform a room based on inputs\n",
        "\n",
        "    Args:\n",
        "        room_image: The input room image to transform\n",
        "        reference_image: The reference image with the desired style\n",
        "        theme: Text description of the theme (e.g., \"modern\", \"vintage\")\n",
        "        room_type: Type of room (e.g., \"living room\", \"bedroom\")\n",
        "        specific_items: Description of specific items to include\n",
        "        include_reference: Whether to include the reference image in the output\n",
        "\n",
        "    Returns:\n",
        "        PIL Image or tuple of PIL Images if include_reference is True\n",
        "    \"\"\"\n",
        "    # Clear GPU memory before starting\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dtype = torch.float16 if device == \"cuda\" else torch.float32  # Use float16 on GPU to reduce memory\n",
        "\n",
        "    print(f\"Using device: {device} with dtype: {dtype}\")\n",
        "\n",
        "    # Memory optimization settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.set_per_process_memory_fraction(0.7)  # Use only 70% of GPU memory\n",
        "\n",
        "    # Load ControlNet model\n",
        "    controlnet = ControlNetModel.from_pretrained(\n",
        "        \"lllyasviel/sd-controlnet-canny\",\n",
        "        torch_dtype=dtype\n",
        "    ).to(device)\n",
        "\n",
        "    # Load Stable Diffusion pipeline with ControlNet\n",
        "    pipeline = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        controlnet=controlnet,\n",
        "        torch_dtype=dtype\n",
        "    ).to(device)\n",
        "\n",
        "    # Load img2img pipeline for refinement\n",
        "    img2img_pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=dtype,\n",
        "        safety_checker=None\n",
        "    ).to(device)\n",
        "\n",
        "    # Enable optimizations for CUDA\n",
        "    if device == \"cuda\":\n",
        "        pipeline.enable_attention_slicing()\n",
        "        pipeline.enable_vae_tiling()\n",
        "        img2img_pipeline.enable_attention_slicing()\n",
        "        img2img_pipeline.enable_vae_tiling()\n",
        "\n",
        "    # Preprocess images\n",
        "    room_image, edge_image = preprocess_image(room_image)\n",
        "    reference_image = analyze_reference_image(reference_image)\n",
        "\n",
        "    # No need for redundant edge detection here since we already have edge_image\n",
        "\n",
        "    # Craft detailed prompt\n",
        "    prompt = f\"\"\"a {theme.lower()} {room_type.lower()},\n",
        "    8k photorealistic, incorporating {specific_items},\n",
        "    perfect symmetry, masterful interior design,\n",
        "    professional photography, ultra-detailed\"\"\"\n",
        "\n",
        "    negative_prompt = \"\"\"poor quality, low resolution, blurry,\n",
        "    bad composition, noisy, grainy, artifacts\"\"\"\n",
        "\n",
        "    print(\"Generating initial image with ControlNet...\")\n",
        "\n",
        "    # Generate initial image with ControlNet\n",
        "    output = pipeline(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=edge_image,\n",
        "        num_inference_steps=30,\n",
        "        guidance_scale=7.5,\n",
        "        controlnet_conditioning_scale=1.0\n",
        "    )\n",
        "    initial_result = output.images[0]\n",
        "    initial_result.save(\"debug/initial_result.png\")\n",
        "\n",
        "    print(\"Refining image with reference style...\")\n",
        "\n",
        "    # Extract reference image features to incorporate in the refinement\n",
        "    # This is a more direct way to utilize the reference image\n",
        "\n",
        "    # Use the reference image to influence the refinement\n",
        "    refine_prompt = prompt + \", style transfer from reference image\"\n",
        "    refined_output = img2img_pipeline(\n",
        "        prompt=refine_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=initial_result,\n",
        "        strength=0.55,\n",
        "        guidance_scale=8.5,\n",
        "        num_inference_steps=50\n",
        "    )\n",
        "\n",
        "    # Get refined result\n",
        "    result = refined_output.images[0]\n",
        "    result.save(\"debug/refined_result.png\")\n",
        "\n",
        "    # Clear memory\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    # Apply post-processing enhancements\n",
        "    result = enhance_output(result)\n",
        "    result.save(\"debug/final_enhanced_result.png\")\n",
        "\n",
        "    # If include_reference is True, return both the reference image and the result\n",
        "    if include_reference:\n",
        "        # Create a copy of the reference image at the same size as the result\n",
        "        reference_copy = reference_image.resize(result.size, Image.LANCZOS)\n",
        "        reference_copy.save(\"debug/reference_resized.png\")\n",
        "\n",
        "        # Return both images\n",
        "        return [result, reference_copy]\n",
        "\n",
        "    # Otherwise return just the result\n",
        "    return result\n",
        "\n",
        "# Create Gradio interface with improved error handling\n",
        "def process_images(room_image, reference_image, theme, room_type, specific_items, include_reference):\n",
        "    \"\"\"Process function for the Gradio interface with error handling\"\"\"\n",
        "    if room_image is None:\n",
        "        return \"Please upload a room image\" if not include_reference else [\"Please upload a room image\", None]\n",
        "    if reference_image is None:\n",
        "        return \"Please upload a reference image\" if not include_reference else [\"Please upload a reference image\", None]\n",
        "\n",
        "    try:\n",
        "        print(f\"Processing with theme: {theme}, room type: {room_type}, include reference: {include_reference}\")\n",
        "        result = transform_room(room_image, reference_image, theme, room_type, specific_items, include_reference)\n",
        "        return result\n",
        "    except RuntimeError as e:\n",
        "        error_msg = f\"GPU memory error: Please try with a smaller image or wait a moment before trying again.\" if \"out of memory\" in str(e) else f\"An error occurred: {str(e)}\"\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return error_msg if not include_reference else [error_msg, None]\n",
        "    except Exception as e:\n",
        "        error_msg = f\"An unexpected error occurred: {str(e)}\"\n",
        "        print(f\"Unexpected error: {str(e)}\")\n",
        "        return error_msg if not include_reference else [error_msg, None]\n",
        "\n",
        "# Create better Gradio interface with more information and reference image toggle\n",
        "interface = gr.Interface(\n",
        "    fn=process_images,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Room Image (Your current room)\"),\n",
        "        gr.Image(type=\"pil\", label=\"Reference Image (Style inspiration)\"),\n",
        "        gr.Textbox(label=\"Theme (e.g., modern, vintage, minimalist)\", value=\"modern\"),\n",
        "        gr.Textbox(label=\"Room Type (e.g., living room, bedroom)\", value=\"living room\"),\n",
        "        gr.Textbox(label=\"Specific Items Description\", value=\"two bamboo plants, a coffee table\"),\n",
        "        gr.Checkbox(label=\"Include Reference Image in Results\", value=False,\n",
        "                    info=\"Display the original reference image alongside the generated result\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Generated Room\"),\n",
        "        gr.Image(type=\"pil\", label=\"Reference Image (Original Style)\", visible=True)\n",
        "    ],\n",
        "    title=\"AI Room Transformer\",\n",
        "    description=\"\"\"Transform your room with AI-powered interior design.\n",
        "    Upload a photo of your room and a reference image for style inspiration.\n",
        "    The AI will generate a new design based on your inputs.\n",
        "    Toggle 'Include Reference Image' to see your style inspiration alongside the result.\n",
        "    Check the 'debug' folder for intermediate results.\"\"\"\n",
        ")\n",
        "\n",
        "# Set Gradio queue for better memory management\n",
        "interface.queue()\n",
        "interface.launch(share=True, debug=True)"
      ]
    }
  ]
}